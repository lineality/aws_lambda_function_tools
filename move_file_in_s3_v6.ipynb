{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "move_file_in_s3_v6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRf8nTEho1hO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "move_file_in_s3\n",
        "\n",
        "Note: the destination 'folder/directory' needs to exist before you move it.\n",
        "\n",
        "Required input parameters:\n",
        "{\n",
        "  \"name_of_target_file\": \"NAME_OF_YOUR_FILE.txt\",\n",
        "  \"target_directory\": \"test_folder/\",\n",
        "  \"s3_bucket_name\": \"xxx\"\n",
        "}\n",
        "\n",
        "\n",
        "This is a function that 'moves' a file in AWS-s3 from one place\n",
        "to another place. More specifically. Before the file is processed it\n",
        "is in one folder (e.g. a folder for files that have NOT been processed), \n",
        "after the file is processed it should be in another folder\n",
        "(e.g. a folder for files that HAVE been processed).\n",
        "\n",
        "In AWS-s3, as in a low-level system, the higher-level process of 'moving' \n",
        "the file is made up of a series of copy and remove steps:\n",
        "\n",
        "Step 1. make a copy of the file in the new folder\n",
        "Step 2. delete the old copy of the file in the original folder\n",
        "\n",
        "The move_file_in_s3 process can be coded as a 'helper function'\n",
        "(outside of the main lambda function), with the following input parameters:\n",
        "\n",
        "\n",
        "\n",
        "The use of try-except is recommended, to handle exceptions etc.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# import python libraries and packages\n",
        "import boto3\n",
        "import json\n",
        "\n",
        " \n",
        "# helper function to move files within AWS s3\n",
        "def move_file_in_s3(s3_resource, s3_bucket_name, target_directory, name_of_target_file, moved_file_destination_in_s3):\n",
        "  \n",
        "    # combine to get your full pathway to file\n",
        "    target_file_and_directory = f\"{target_directory}{name_of_target_file}\"\n",
        "\n",
        "    # set your variables\n",
        "    original_key = target_file_and_directory\n",
        "    destination_key = moved_file_destination_in_s3 + name_of_target_file\n",
        "\n",
        "    original_file_data = {\n",
        "        'Bucket': s3_bucket_name,\n",
        "        'Key': original_key\n",
        "    }\n",
        "\n",
        "    # COPY the file (so then in two places, two copies)\n",
        "    s3_resource.meta.client.copy(original_file_data, s3_bucket_name, destination_key)\n",
        "\n",
        "    # Delete the former item (leaving only the moved item)\n",
        "    s3_resource.Object(s3_bucket_name, original_key).delete()\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# Sample Input: \n",
        "\n",
        "{\n",
        "  \"name_of_target_file\": \"NAME_OF_YOUR_FILE.txt\",\n",
        "  \"target_directory\": \"test_folder/\",\n",
        "  \"s3_bucket_name\": \"xxx\"\n",
        "}\n",
        "\"\"\"\n",
        "################\n",
        "# Main Function\n",
        "################\n",
        "def lambda_handler(event, context):\n",
        " \n",
        "    #############################################\n",
        "    # Setup, inputs, connections, variables, etc.\n",
        "    #############################################\n",
        "\n",
        "    #####################\n",
        "    # get moved_file_destination_in_s3\n",
        "    #####################\n",
        "    # Test for input:\n",
        "    try:\n",
        "        moved_file_destination_in_s3 = event[\"moved_file_destination_in_s3\"]\n",
        "\n",
        "    except Exception as e:\n",
        " \n",
        "        # if no input specified, set to default:\n",
        "        moved_file_destination_in_s3 = \"files_processed_all_done/\"\n",
        "\n",
        "    #####################\n",
        "    # get s3_bucket_name\n",
        "    #####################\n",
        "    # Test for input:\n",
        "    try:\n",
        "        s3_bucket_name = event[\"s3_bucket_name\"]\n",
        "\n",
        "    except Exception as e:\n",
        " \n",
        "        output = f\"\"\"Error: No input for (field=) s3_bucket_name \n",
        "        Error Message = '{str(e)} \n",
        "        \"\"\"\n",
        "        \n",
        "        # print for terminal\n",
        "        print(output)\n",
        "\n",
        "        statusCode = 403\n",
        "\n",
        "        # End the lambda function\n",
        "        return {\n",
        "            'statusCode': statusCode,\n",
        "            'body': output\n",
        "        }\n",
        "\n",
        "    ################################\n",
        "    # get name_of_target_file in s3\n",
        "    ################################\n",
        "    # Test for input:\n",
        "    try:\n",
        "        name_of_target_file = event[\"name_of_target_file\"]\n",
        "\n",
        "    except Exception as e:\n",
        " \n",
        "        output = f\"\"\"Error: No input for (field=)name_of_target_file \n",
        "        Error Message = '{str(e)} \n",
        "        \"\"\"\n",
        "        \n",
        "        # print for terminal\n",
        "        print(output)\n",
        "\n",
        "        statusCode = 403\n",
        "\n",
        "        # End the lambda function\n",
        "        return {\n",
        "            'statusCode': statusCode,\n",
        "            'body': output\n",
        "        }\n",
        "\n",
        "\n",
        "    #############################\n",
        "    # get target_directory in s3\n",
        "    #############################\n",
        "    # Test for input:\n",
        "    try:\n",
        "        target_directory = event[\"target_directory\"]\n",
        "\n",
        "        # check that target directory is followed by a '/'\n",
        "        if target_directory[-1] != '/':\n",
        "              target_directory = target_directory + '/'\n",
        "\n",
        "    except Exception as e:\n",
        " \n",
        "        output = f\"\"\"Error: No input for (field=)directory_name \n",
        "        Error Message = '{str(e)} \n",
        "        \"\"\"\n",
        "        \n",
        "        # print for terminal\n",
        "        print(output)\n",
        "\n",
        "        statusCode = 403\n",
        "\n",
        "        # End the lambda function\n",
        "        return {\n",
        "            'statusCode': statusCode,\n",
        "            'body': output\n",
        "        }\n",
        "\n",
        "\n",
        "    ####################################\n",
        "    # S3: Connect to S3 (Make resource)\n",
        "    ####################################\n",
        "\n",
        "    try:\n",
        "        # Set Constants\n",
        "        AWS_REGION = \"us-east-1\"\n",
        "\n",
        "        # make s3_resource\n",
        "        s3_resource = boto3.resource(\"s3\", region_name=AWS_REGION)\n",
        "\n",
        "        s3_bucket = s3_resource.Bucket(s3_bucket_name)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        " \n",
        "        output = f\"\"\"Error: Could not connect to AWS S3.\n",
        "        Error Message = '{str(e)} \n",
        "        \"\"\"\n",
        "        \n",
        "        # print for terminal\n",
        "        print(output)\n",
        "\n",
        "        statusCode = 403\n",
        "\n",
        "        # End the lambda function\n",
        "        return {\n",
        "            'statusCode': statusCode,\n",
        "            'body': output\n",
        "        }\n",
        "\n",
        "\n",
        "    ######################\n",
        "    # Relocate File In S3\n",
        "    ######################\n",
        "    \"\"\"\n",
        "    If what you are doing with the file is completed, then move the file\n",
        "    into a 'we_are_finished_with_these_files' directory.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # move file\n",
        "        move_file_in_s3(s3_resource, s3_bucket_name, target_directory, name_of_target_file, moved_file_destination_in_s3)\n",
        "        pass\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "      \n",
        "        output = f\"\"\"Error: Error with relocating files inside s3\n",
        "        Error Message = '{str(e)}\n",
        "        \"\"\"\n",
        "        # print for terminal\n",
        "        print(output)\n",
        "\n",
        "        statusCode = 430\n",
        "\n",
        "        # End the lambda function\n",
        "        return {\n",
        "            'statusCode': statusCode,\n",
        "            'body': output\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    #########\n",
        "    # Finish\n",
        "    #########\n",
        "\n",
        "    return {\n",
        "        'statusCode': 200,\n",
        "        'body': json.dumps(f\"Completed file moved: '{name_of_target_file}'', OK!\")\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "s3 = boto3.resource('s3')\n",
        "copy_source = {\n",
        "    'Bucket': 'mybucket',\n",
        "    'Key': 'mykey'\n",
        "}\n",
        "s3.meta.client.copy(copy_source, 'otherbucket', 'otherkey')"
      ],
      "metadata": {
        "id": "ju7PCF6zMKO4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}